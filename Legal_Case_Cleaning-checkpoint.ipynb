{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "os.chdir(r'\\\\phont80025us.homeoffice.wal-mart.com\\Shares\\Audit_Analytics\\FY20\\Risk Sensing\\Auto Care Center\\ACC_TBC_Cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Consolidate the information of 117 cases into readable data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = pd.read_excel('ACC  TBC Cases Data - master doc.xlsx',sheet_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Create index indicating the 1st row and last row of each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "df_index = pd.DataFrame(columns=['Case_#','Master_ix','Sub_ix_Start','Sub_ix_End'])\n",
    "for i in range(117):\n",
    "    try:\n",
    "        df_index.loc[i+1,'Case_#'] = i+1\n",
    "        df_index.loc[i+1,'Master_ix'] = raw[raw.iloc[:,0] ==i+1].index[0]\n",
    "        df_index.loc[i+1,'Sub_ix_Start'] = raw[raw.iloc[:,0] ==i+1].index[1]\n",
    "        df_index.loc[i+1,'Sub_ix_End'] = raw[raw.iloc[:,0] ==i+2].index[1]\n",
    "    except IndexError:\n",
    "        print(i+1)\n",
    "\n",
    "df_index.loc[117,'Sub_ix_End'] = len(raw)\n",
    "\n",
    "df_index['No._Col'] = df_index['Sub_ix_End']-df_index['Sub_ix_Start']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Some cases have different format\n",
    "- check the differences, then convert to the standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_#</th>\n",
       "      <th>Master_ix</th>\n",
       "      <th>Sub_ix_Start</th>\n",
       "      <th>Sub_ix_End</th>\n",
       "      <th>No._Col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>99</td>\n",
       "      <td>1313</td>\n",
       "      <td>1349</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>106</td>\n",
       "      <td>1524</td>\n",
       "      <td>1560</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>140</td>\n",
       "      <td>2645</td>\n",
       "      <td>2681</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>152</td>\n",
       "      <td>3031</td>\n",
       "      <td>3067</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>166</td>\n",
       "      <td>3487</td>\n",
       "      <td>3523</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>177</td>\n",
       "      <td>3838</td>\n",
       "      <td>3874</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>106</td>\n",
       "      <td>178</td>\n",
       "      <td>3874</td>\n",
       "      <td>3910</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>186</td>\n",
       "      <td>4155</td>\n",
       "      <td>4191</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case_# Master_ix Sub_ix_Start Sub_ix_End No._Col\n",
       "33      33        99         1313       1349      36\n",
       "39      39       106         1524       1560      36\n",
       "71      71       140         2645       2681      36\n",
       "82      82       152         3031       3067      36\n",
       "95      95       166         3487       3523      36\n",
       "105    105       177         3838       3874      36\n",
       "106    106       178         3874       3910      36\n",
       "114    114       186         4155       4191      36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the description table for each case is supposed to have 35 rows\n",
    "# check which case contains more than 35 rows and fix the exceptions\n",
    "\n",
    "df_exception = df_index[df_index['No._Col'] != 35]\n",
    "df_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See the standardize row names for each case\n",
    "start = df_index.iloc[0,2]\n",
    "end = df_index.iloc[0,3]\n",
    "case_sample= raw.iloc[start:end,[0,5]]  \n",
    "\n",
    "sd_col = case_sample.iloc[:,0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Case', 33, set([nan]))\n",
      "('Case', 39, set([nan]))\n",
      "('Case', 71, set([nan]))\n",
      "('Case', 82, set([nan]))\n",
      "('Case', 95, set([u'Expert witnesses']))\n",
      "('Case', 105, set([nan]))\n",
      "('Case', 106, set([nan]))\n",
      "('Case', 114, set([nan]))\n"
     ]
    }
   ],
   "source": [
    "# check the difference exist in each exception case\n",
    "for i in range(len(df_exception)):\n",
    "    \n",
    "    start = df_exception.iloc[i,2]    \n",
    "    end = df_exception.iloc[i,3]\n",
    "    exp_case = raw.iloc[start:end,[0,5]]\n",
    "    exp_col = exp_case.iloc[:,0][1:]\n",
    "    \n",
    "    print('Case' , df_exception.iloc[i,0],set(exp_col) -set(sd_col ),)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some discription text for above case are split into 2 rows\n",
    "# so that the name of the discription in a second row is NAN\n",
    "\n",
    "drop_row = []\n",
    "for i in range(len(df_exception)):\n",
    "    try:\n",
    "        start = df_exception.iloc[i,2]    \n",
    "        end = df_exception.iloc[i,3]\n",
    "        exp_case = raw.iloc[start:end,[0,5]]     \n",
    "        drop_ix  = exp_case[exp_case.iloc[:,0].isnull()].index[0]\n",
    "        drop_row = drop_row + [drop_ix]\n",
    "        raw.iloc[drop_ix-1,5] = raw.loc[drop_ix-1,'Unnamed: 5'] + raw.loc[drop_ix,'Unnamed: 5']\n",
    "    except IndexError:\n",
    "        drop_ix  = exp_case[exp_case.iloc[:,0] == u'Expert witnesses'].index[0]\n",
    "        drop_row = drop_row + [drop_ix]\n",
    "#raw = raw.drop(drop_row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_case_all = pd.DataFrame()\n",
    "remove_list  = ['Services:','ACC Documentation:','Tire Sale:','Incident:','Lawsuit:',u'Expert witnesses']\n",
    "\n",
    "for i in range(117):\n",
    "    start = df_index.iloc[i,2]\n",
    "    end = df_index.iloc[i,3]\n",
    "    df_case = raw.iloc[start:end,[0,5]]  \n",
    "    remove_bool =[(j not in remove_list) and (type(j) != int) for j in df_case.iloc[:,0]]    \n",
    "    df_case = df_case[remove_bool].T\n",
    "    \n",
    "    df_case.columns = df_case.iloc[0,:]\n",
    "    df_case = df_case.iloc[1:2,:]\n",
    "    #print(df_case.shape[1],i)\n",
    "    df_case_all = pd.concat([df_case_all, df_case])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = [i for i in sd_col if i not in  remove_list]\n",
    "df_case_all = df_case_all[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_case_all.index = range(len(df_case_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clean individual columns in the standard format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  2.1 Process Service Date, Accident Date, Date Opened, and Date Closed\n",
    "- Clean various data format\n",
    "- Create 3 columns:\n",
    "   \n",
    "    Days_1stServ_Incd: days inbetween 1st service and the day of incident\n",
    "    \n",
    "    Days_1stServ_opd: days inbetween 1st service and case open day\n",
    "    \n",
    "    Days_1stServ_cld: days inbetween 1st service and case close day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September, 2008 (allegedly)\n"
     ]
    }
   ],
   "source": [
    "# among the cases, this case have no info of date of service, set it to September 15, 2008 \n",
    "print(df_case_all.loc[7,'Date of service'])\n",
    "df_case_all.loc[7,'Date of service'] = 'September 15, 2008'\n",
    "datepattern = re.compile(\"\\w* \\d*, \\d{4}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the set of strings which have the Month Day,Year format\n",
    "\n",
    "for i in df_case_all.index: \n",
    "\n",
    "    try: \n",
    "        time  = datepattern.findall(df_case_all.loc[i,'Date of service'])\n",
    "        df_case_all.loc[i,'Date_1stService'] = datetime.strptime(time[0],'%B %d, %Y').strftime('%m/%d/%Y') \n",
    "        Incd =  datetime.strptime(df_case_all.loc[i,'Incident date'],'%B %d, %Y')\n",
    "        df_case_all.loc[i,'Days_1stServ_Incd'] = (Incd - datetime.strptime(time[0],'%B %d, %Y')).days\n",
    "        \n",
    "        opd = datetime.strptime(df_case_all.loc[i,'Date Opened'],'%B %d, %Y')        \n",
    "        df_case_all.loc[i,'Days_1stServ_opd'] = (opd - datetime.strptime(time[0],'%B %d, %Y')).days\n",
    "        \n",
    "        cld = datetime.strptime(df_case_all.loc[i,'Date Closed'],'%B %d, %Y')      \n",
    "        df_case_all.loc[i,'Days_1stServ_cld'] = (cld - datetime.strptime(time[0],'%B %d, %Y')).days\n",
    "    \n",
    "    except: \n",
    "        #print (df_case_all.loc[i,'Date Closed'])\n",
    "        df_case_all.loc[i,'Days_1stServ_cld'] = np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  2.2 Process Store Number and State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# the element under \"Store\" column is in this format : store number store name\n",
    "# except for one case: \n",
    "# 'ACC – 579 St. Augustine, Florida / TBC – 8138 Daytona Beach, Florida'\n",
    "def stor_nb(s):\n",
    "    mo = re.match('.+([0-9])[^0-9]*$',s)\n",
    "    store_nb = s[0:mo.end(1)]    \n",
    "    return(int(store_nb))\n",
    "\n",
    "Store_nb =  []\n",
    "for i in df_case_all.index:   \n",
    "    try:\n",
    "        Store_nb = Store_nb + [stor_nb(df_case_all.loc[i,'Store'])]       \n",
    "        df_case_all.loc[i,'State'] = df_case_all['Store'][i].split(',')[-1]\n",
    "        \n",
    "    except UnicodeEncodeError:\n",
    "        Store_nb =  Store_nb +[8138]\n",
    "        df_case_all.loc[i,'State'] = 'Florida'\n",
    "\n",
    "df_case_all['Store_nb'] = Store_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Process Vehicle Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ix = df_case_all[df_case_all['Vehicle'].isnull()].index\n",
    "df_case_all.loc[ix,'Vehicle'] = 'unknown'\n",
    "df_case_all['Vehicle'] = df_case_all['Vehicle'].apply(lambda x:x.replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create columns to store 4 types of Vehicle information:\n",
    "### 'Mileage'\n",
    "### 'Veh_Yr'\n",
    "### 'Veh_Brand'\n",
    "### 'Veh_Model'\n",
    "\n",
    "for i in df_case_all.index:\n",
    "\n",
    "    if '/ Mileage' in df_case_all.loc[i,'Vehicle']:\n",
    "        \n",
    "        text1 = df_case_all.loc[i,'Vehicle'].split('/ Mileage')[1]\n",
    "            \n",
    "        if ('unknown' in text1)|('not' in text1):\n",
    "            df_case_all.loc[i,'Mileage'] =  np.nan            \n",
    "        else: \n",
    "            try: df_case_all.loc[i,'Mileage'] = re.findall(r'\\d+',text1)[0]\n",
    "            except IndexError: df_case_all.loc[i,'Mileage'] =  np.nan\n",
    "                \n",
    "        text2 = df_case_all.loc[i,'Vehicle'].split('/ Mileage')[0]        \n",
    "        try: \n",
    "            df_case_all.loc[i,'Veh_Yr'] = int(re.findall(r'\\d+',text2)[0])\n",
    "            text3 = text2[5:]\n",
    "            df_case_all.loc[i,'Veh_Brand'] = text3.split(' ',1)[0]\n",
    "            df_case_all.loc[i,'Veh_Model'] = text3.split(' ',1)[1]\n",
    "            \n",
    "        except IndexError: \n",
    "            df_case_all.loc[i,'Veh_Yr'] = np.nan \n",
    "            df_case_all.loc[i,'Veh_Brand'] = text2.split(' ',1)[0]\n",
    "            df_case_all.loc[i,'Veh_Model'] = text2.split(' ',1)[1]\n",
    "                        \n",
    "        \n",
    "    else: \n",
    "        \n",
    "        df_case_all.loc[i,'Mileage'] =  np.nan\n",
    "        Veh = df_case_all.loc[i,'Vehicle']\n",
    "        if ('unknown' in Veh)|('not' in Veh)|('Unknown' in Veh):\n",
    "            df_case_all.loc[i,'Veh_Yr'] = np.nan\n",
    "            df_case_all.loc[i,'Veh_Brand'] = np.nan\n",
    "            df_case_all.loc[i,'Veh_Model'] = np.nan\n",
    "        else:\n",
    "            try:\n",
    "                df_case_all.loc[i,'Veh_Yr'] = re.findall(r'\\d+',Veh)[0]\n",
    "                text4 = df_case_all.loc[i,'Vehicle'][5:]\n",
    "                df_case_all.loc[i,'Veh_Brand'] = text4.split(' ',1)[0]\n",
    "                df_case_all.loc[i,'Veh_Model'] = text4.split(' ',1)[1]\n",
    "            except IndexError:            \n",
    "                df_case_all.loc[i,'Veh_Brand'] = Veh.split(' ',1)[0]\n",
    "                df_case_all.loc[i,'Veh_Model'] = Veh.split(' ',1)[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Calculate service time\n",
    "\n",
    "- if the cases have multiple services, keep the longest service time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ix = df_case_all[df_case_all['Arrival & service complete times'].isnull()].index\n",
    "df_case_all.loc[ix,'Arrival & service complete times'] = 'unknown'\n",
    "for i in df_case_all.index:\n",
    "    #print(i)\n",
    "    text = df_case_all.loc[i,'Arrival & service complete times']\n",
    "    if  ('Unknown' in text)|('unknown' in text)|('no' in text)|('not' in text):\n",
    "        df_case_all.loc[i,'Sev_Time'] = np.nan\n",
    "   \n",
    "    else:\n",
    "        \n",
    "        timepattern = re.compile(\"\\d*:\\d{2}\")\n",
    "        time  = timepattern.findall(text)\n",
    "        APM = re.findall(\"AM|PM\", text)\n",
    "        \n",
    "        for j in range(len(time)):\n",
    "            if (APM[j] == 'PM') & (int(time[j].split(\":\")[0])<12):\n",
    "                time[j] = (int(time[j].split(\":\")[0])+12) * 60 + int(time[j].split(\":\")[1])\n",
    "            else: time[j] = int(time[j].split(\":\")[0]) * 60  + int(time[j].split(\":\")[1])\n",
    "        \n",
    "        temp_max = time[1]-time[0]\n",
    "        for k in range(1,len(time)/2):\n",
    "            if time[2*k+1]-time[2*k] > temp_max: temp_max = time[2*k+1]-time[2*k]\n",
    "        df_case_all.loc[i,'Sev_Time'] = temp_max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5 Create dummy columns for various service\n",
    "- Tire Installation\n",
    "- Tire Rotation\n",
    "- Tire Repair\n",
    "- Oil Change\n",
    "- Battery\n",
    "- Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_case_all['Tire Installation'] = 0\n",
    "df_case_all['Tire Rotation'] = 0\n",
    "df_case_all['Tire Repair'] = 0\n",
    "df_case_all['Oil Change'] = 0 \n",
    "df_case_all['Battery'] = 0\n",
    "#df_case_all['Others'] = 0\n",
    "\n",
    "\n",
    "\n",
    "bool1 = ['install' in  df_case_all.loc[i,'Services/Products provided'].lower() for i in df_case_all.index]\n",
    "ix1   = df_case_all[bool1].index\n",
    "df_case_all.loc[ix1, 'Tire Installation'] = 1\n",
    "\n",
    "bool2 = ['rotat' in  df_case_all.loc[i,'Services/Products provided'].lower() for i in df_case_all.index]\n",
    "ix2   = df_case_all[bool2].index\n",
    "df_case_all.loc[ix2, 'Tire Rotation'] = 1\n",
    "\n",
    "bool3 = ['repair' in  df_case_all.loc[i,'Services/Products provided'].lower() for i in df_case_all.index]\n",
    "ix3   = df_case_all[bool3].index\n",
    "df_case_all.loc[ix3, 'Tire Repair'] = 1\n",
    "\n",
    "bool4 = ['oil change' in  df_case_all.loc[i,'Services/Products provided'].lower() for i in df_case_all.index]\n",
    "ix4   = df_case_all[bool4].index\n",
    "df_case_all.loc[ix4, 'Oil Change'] = 1\n",
    "\n",
    "bool5 = ['battery' in  df_case_all.loc[i,'Services/Products provided'].lower() for i in df_case_all.index]\n",
    "ix5   = df_case_all[bool5].index\n",
    "df_case_all.loc[ix5, 'Battery'] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.6 Check how many associates were involved in the provided services and if QC involved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ix = df_case_all[df_case_all['Service technicians'].isnull()].index\n",
    "df_case_all.loc[ix,'Service technicians'] = 'unknown'\n",
    "\n",
    "\n",
    "df_case_all['Count_Ser_Asso'] = np.nan\n",
    "df_case_all['QC?'] = 0\n",
    "\n",
    "assopat = re.compile('\\d+') \n",
    "for i in df_case_all.index:\n",
    "    \n",
    "    text = df_case_all.loc[i,'Service technicians'].lower()\n",
    "    #print(i,text)\n",
    "    if ('unknown' in text)|('not' in text)|('none' in text):\n",
    "        df_case_all.loc[i,'Count_Ser_Asso'] = -1\n",
    "        df_case_all.loc[i,'QC?'] = -1\n",
    "    else:\n",
    "        # check if QC involved\n",
    "        if 'quality' in text:\n",
    "            df_case_all.loc[i,'QC?'] = 1\n",
    "        else: df_case_all.loc[i,'QC?'] = 0\n",
    "        \n",
    "        # if there are multiple times of services, used the info of 1st service        \n",
    "        ser_date =  datepattern.findall(text)\n",
    "        \n",
    "        if len(ser_date)>1:\n",
    "            begin = text.find(ser_date[0])+ len(ser_date[0])\n",
    "            cut = text.find(ser_date[1])-1\n",
    "            text = text[begin:cut]            \n",
    "            \n",
    "            df_case_all.loc[i,'Count_Ser_Asso'] = len(assopat.findall(text))\n",
    "            \n",
    "        elif len(ser_date)==1:\n",
    "            begin = text.find(ser_date[0])+ len(ser_date[0])\n",
    "            text = text[begin:] \n",
    "            df_case_all.loc[i,'Count_Ser_Asso'] = len(assopat.findall(text))\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if len(assopat.findall(text))>0:\n",
    "                df_case_all.loc[i,'Count_Ser_Asso'] = len(assopat.findall(text))\n",
    "            else: \n",
    "                \n",
    "                text = text.replace('/greeter',\"\")\n",
    "                df_case_all.loc[i,'Count_Ser_Asso'] = text.count('/')+text.count('and ')+1\n",
    "                \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.7 Clean up Defense costs and Payout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "money = re.compile(r\"\\$\\d*\")\n",
    "for i in df_case_all.index:\n",
    "    #Clean Payout\n",
    "    try:\n",
    "        pay  = money.findall(df_case_all.loc[i,'Payout'].replace(\",\",\"\"))       \n",
    "        df_case_all.loc[i,'Payout'] = int(pay[0].replace(\"$\",\"\"))\n",
    "        \n",
    "    except AttributeError:  df_case_all.loc[i,'Payout'] = df_case_all.loc[i,'Payout']\n",
    "    except IndexError: df_case_all.loc[i,'Payout']  = 0\n",
    "\n",
    "    #Clean Defense costs\n",
    "    try:\n",
    "        cost  = money.findall(df_case_all.loc[i,'Defense costs'].replace(\",\",\"\")) \n",
    "        #print(i,df_case_all.loc[i,'Defense costs'],cost)\n",
    "        df_case_all.loc[i,'Defense costs'] = int(cost[0].replace(\"$\",\"\"))\n",
    "    except AttributeError: df_case_all.loc[i,'Defense costs'] = df_case_all.loc[i,'Defense costs'] \n",
    "    except IndexError: df_case_all.loc[i,'Defense costs']  = 0       \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.8 Multiple cases will be initiated for 1 incident\n",
    "- Keep one line of the incident and sum up the payout and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Duplicated Cases\n",
    "\n",
    "df_dupl_case  = df_case_all[['related' in i for i in df_case_all['Matter number']]].sort_values(by=['Customer'])\n",
    "\n",
    "for i in df_dupl_case['Customer'].unique():\n",
    "    ix  = df_dupl_case[df_dupl_case['Customer'] == i].index\n",
    "    df_dupl_case.loc[ix,'Defense costs'] = sum(df_dupl_case.loc[ix,'Defense costs'])\n",
    "    df_dupl_case.loc[ix,'Payout'] = sum(df_dupl_case.loc[ix,'Payout'])\n",
    "\n",
    "df_sub = df_dupl_case.drop_duplicates(['Customer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_no_dupl = df_case_all[[ i not in df_dupl_case.index for i in  df_case_all.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_case_clean = pd.concat([df_no_dupl,df_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_case_clean.to_csv('acc_cleaned.csv',index = False,encoding='utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda2]",
   "language": "python",
   "name": "Python [Anaconda2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
